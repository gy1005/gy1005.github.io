[{"authors":["admin"],"categories":null,"content":"I am a 4th year Ph.D. student in Electrical and Computer Engineering at Cornell University, advised by Professor Christina Delimitrou. I am interested in microservices, cloud computing, computer architecture and computer systems. My research focuses on building and managing large-scale microservices in datacenters, improving their performance and resource efficiency. Before studying at Cornell, I obtained my B.Eng. degree in Electronic Engineering from Tsinghua University in 2016.\nI was a Ph.D. software engineering intern at Google in 2018 and 2019 hosted by David Lo and Sundar Dev. During my internship, I did research on using machine learning to improve resource efficiency and detect performance issues in Google Cloud.\n","date":1570556999,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1570556999,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://gy1005.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am a 4th year Ph.D. student in Electrical and Computer Engineering at Cornell University, advised by Professor Christina Delimitrou. I am interested in microservices, cloud computing, computer architecture and computer systems. My research focuses on building and managing large-scale microservices in datacenters, improving their performance and resource efficiency. Before studying at Cornell, I obtained my B.Eng. degree in Electronic Engineering from Tsinghua University in 2016.\nI was a Ph.D. software engineering intern at Google in 2018 and 2019 hosted by David Lo and Sundar Dev.","tags":null,"title":"Yu Gan","type":"author"},{"authors":["**Yu Gan**","Yanqi Zhang","Kelvin Hu","Dailun Cheng","Yuan He","Meghna Pancholi","Christina Delimitrou"],"categories":null,"content":"","date":1564459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570557062,"objectID":"5607062ccec1ecb67b2e4ba2ff67867c","permalink":"https://gy1005.github.io/publication/2019.sigops.seer/","publishdate":"2019-07-30T00:00:00-04:00","relpermalink":"/publication/2019.sigops.seer/","section":"publication","summary":"Performance unpredictability is a major roadblock towards cloud adoption, and has performance, cost, and revenue ramifications. Predictable performance is even more critical as cloud services transition from monolithic designs to microservices. Detecting QoS violations after they occur in systems with microservices results in long recovery times, as hotspots propagate and amplify across dependent services. We present Seer, an online cloud performance debugging system that leverages deep learning and the massive amount of tracing data cloud systems collect to learn spatial and temporal patterns that translate to QoS violations. Seer combines lightweight distributed RPC-level tracing, with detailed low-level hardware monitoring to signal an upcoming QoS violation, and diagnose the source of unpredictable performance. Once an imminent QoS violation is detected, Seer notifies the cluster manager to take action to avoid performance degradation altogether. We evaluate Seer both in local clusters, and in large-scale deployments of end-to-end applications built with microservices with hundreds of users. We show that Seer correctly anticipates QoS violations 91% of the time, and avoids the QoS violation to begin with in 84% of cases. Finally, we show that Seer can identify application-level design bugs, and provide insights on how to better architect microservices to achieve predictable performance.","tags":[],"title":"Leveraging Deep Learning to Improve Performance Predictability in Cloud Microservices with Seer","type":"publication"},{"authors":["**Yu Gan**","Yanqi Zhang","Dailun Cheng","Ankitha Shetty","Priyal Rathi","Nayantara Katarki","Ariana Bruno","Justin Hu","Brian Ritchken","Brendon Jackson","Kelvin Hu","Meghna Pancholi","Yuan He","Brett Clancy","Chris Colen","Fukang Wen","Catherine Leung","Siyuan Wang","Leon Zaruvinsky","Mateo Espinosa","Rick Lin","Zhongling Liu","Jake Padilla","Christina Delimitrou"],"categories":null,"content":"","date":1555300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570556999,"objectID":"20e64054b4f06654ee944848c9c61146","permalink":"https://gy1005.github.io/publication/2019.asplos.deathstarbench/","publishdate":"2019-04-15T00:00:00-04:00","relpermalink":"/publication/2019.asplos.deathstarbench/","section":"publication","summary":"Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present DeathStarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail at scale effects of microservices in real deployments with hundreds of users, and highlight the increased pressure they put on performance predictability.","tags":[],"title":"An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud and Edge Systems","type":"publication"},{"authors":["**Yu Gan**","Yanqi Zhang","Kelvin Hu","Yuan He","Meghna Pancholi","Dailun Cheng","Christina Delimitrou"],"categories":null,"content":"","date":1555300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570556999,"objectID":"6262b94a41de3a7061c78e3ea67e0cf9","permalink":"https://gy1005.github.io/publication/2019.asplos.seer/","publishdate":"2019-04-15T00:00:00-04:00","relpermalink":"/publication/2019.asplos.seer/","section":"publication","summary":"Performance unpredictability is a major roadblock towards cloud adoption, and has performance, cost, and revenue ramifications. Predictable performance is even more critical as cloud services transition from monolithic designs to microservices. Detecting QoS violations after they occur in systems with microservices results in long recovery times, as hotspots propagate and amplify across dependent services. We present Seer, an online cloud performance debugging system that leverages deep learning and the massive amount of tracing data cloud systems collect to learn spatial and temporal patterns that translate to QoS violations. Seer combines lightweight distributed RPC-level tracing, with detailed low-level hardware monitoring to signal an upcoming QoS violation, and diagnose the source of unpredictable performance. Once an imminent QoS violation is detected, Seer notifies the cluster manager to take action to avoid performance degradation altogether. We evaluate Seer both in local clusters, and in large-scale deployments of end-to-end applications built with microservices with hundreds of users. We show that Seer correctly anticipates QoS violations 91% of the time, and avoids the QoS violation to begin with in 84% of cases. Finally, we show that Seer can identify applicationlevel design bugs, and provide insights on how to better architect microservices to achieve predictable performance.","tags":[],"title":"Seer: Leveraging Big Data to Navigate the Complexity of Performance Debugging in Cloud Microservices","type":"publication"},{"authors":["Yanqi Zhang","**Yu Gan**","Christina Delimitrou"],"categories":null,"content":"","date":1553486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570556999,"objectID":"58004ce8776de17340c15e582107ea9c","permalink":"https://gy1005.github.io/publication/2019.ispass.uqsim/","publishdate":"2019-03-25T00:00:00-04:00","relpermalink":"/publication/2019.ispass.uqsim/","section":"publication","summary":"Current cloud services are moving away from monolithic designs and towards graphs of many looselycoupled, single-concerned microservices. Microservices have several advantages, including speeding up development and deployment, allowing specialization of the software infrastructure, and helping with debugging and error isolation. At the same time they introduce several hardware and software challenges. Given that most of the performance and efficiency implications of microservices happen at scales larger than what is available outside production deployments, studying such effects requires designing the right simulation infrastructures. We present µqSim, a scalable and validated queueing network simulator designed specifically for interactive microservices. µqSim provides detailed intra- and inter-microservice models that allow it to faithfully reproduce the behavior of complex, many-tier applications. µqSim is also modular, allowing reuse of individual models across microservices and end-toend applications. We have validated µqSim both against simple and more complex microservices graphs, and have shown that it accurately captures performance in terms of throughput and tail latency. Finally, we use µqSim to model the tail at scale effects of request fanout, and the performance impact of power management in latency-sensitive microservices.","tags":[],"title":"μqSim: Enabling Accurate and Scalable Simulation for Interactive Microservices","type":"publication"},{"authors":["**Yu Gan**","Meghna Pancholi","Dailun Cheng","Siyuan Hu","Yuan He","Christina Delimitrou"],"categories":null,"content":"","date":1530417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552527587,"objectID":"bff9a51877718e8b8d439bdf85a9e2c6","permalink":"https://gy1005.github.io/publication/2018.hotcloud.seer/","publishdate":"2018-07-01T00:00:00-04:00","relpermalink":"/publication/2018.hotcloud.seer/","section":"publication","summary":"Performance unpredictability in cloud services leads to poor user experience, degraded availability, and has revenue ramifications. Detecting performance degradation a posteriori helps the system take corrective action, but does not avoid the QoS violations. Detecting QoS violations after the fact is even more detrimental when a service consists of hundreds of thousands of loosely-coupled microservices, since performance hiccups can quickly propagate across the dependency graph of microservices. In this work we focus on anticipating QoS violations in cloud settings to mitigate performance unpredictability to begin with. We propose Seer, a cloud runtime that leverages the massive amount of tracing data cloud systems collect over time and a set of practical learning techniques to signal upcoming QoS violations, as well as identify the microservice(s) causing them. Once an imminent QoS violation is detected Seer uses machine-level hardware events to determine the cause of the QoS violation, and adjusts the resource allocations to prevent it. In local clusters with 10 40-core servers and 200-instance clusters on GCE running diverse cloud microservices, we show that Seer correctly anticipates QoS violations 91% of the time, and attributes the violation to the correct microservice in 89% of cases. Finally, Seer detects QoS violations early enough for a corrective action to almost always be applied successfully.","tags":[],"title":"Seer: Leveraging Big Data to Navigate the Increasing Complexity of Cloud Debugging","type":"publication"},{"authors":["**Yu Gan**","Christina Delimitrou"],"categories":null,"content":"","date":1530417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570556999,"objectID":"b385e9d381d6975227c24b6ae1293d25","permalink":"https://gy1005.github.io/publication/2018.cal.deathstarbench/","publishdate":"2018-07-01T00:00:00-04:00","relpermalink":"/publication/2018.cal.deathstarbench/","section":"publication","summary":"","tags":[],"title":"The Architectural Implications of Cloud Microservices","type":"publication"},{"authors":["**Yu Gan**","Chunxiao Jiang ","Norman C. Beaulieu","Jian Wang","Yong Ren"],"categories":null,"content":"","date":1471320000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570556999,"objectID":"ccb5dbbf2e72302e486ad5aae5a2c4d8","permalink":"https://gy1005.github.io/publication/2016.tcomm.peer-predition/","publishdate":"2016-08-16T00:00:00-04:00","relpermalink":"/publication/2016.tcomm.peer-predition/","section":"publication","summary":"Collaborative spectrum sensing is an effective method to improve detection rates in cognitive radio networks. However, it is vulnerable to spectrum sensing data falsification (SSDF) attacks when malicious secondary users (SUs) report fraudulent sensing data. In order to improve the robustness, numerous attack prevention schemes have been proposed to identify malicious SUs. Nevertheless, most of them neglect to incentivize SUs to send truthful reports. An incentive method based on peer-prediction is proposed to identify malicious suspects, punish attackers, and incentivize SUs to send truthful reports simultaneously for decision fusion. Moreover, continuous peer-prediction derived from the binary case is introduced, which is capable of preventing attacks in the continuous domain. Theoretical analysis and simulation results demonstrate that honest SUs are rewarded for accurate and truthful sensing results, while malicious SUs incur penalty for making falsified sensing reports. A significant improvement of detection rates is obtained by the proposed scheme when there are no more than half of malicious SUs conducting SSDF attacks.","tags":[],"title":"Secure Collaborative Spectrum Sensing: A Peer-Prediction Method","type":"publication"},{"authors":["**Yu Gan**","Chunxiao Jiang","Wei Zhang","Norman C. Beaulieu","Yong Ren"],"categories":null,"content":"","date":1450155600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570556999,"objectID":"df40f2df8b4535616e5480bcd9187566","permalink":"https://gy1005.github.io/publication/2015.globecom.peer-predition/","publishdate":"2015-12-15T00:00:00-05:00","relpermalink":"/publication/2015.globecom.peer-predition/","section":"publication","summary":"Collaborative spectrum sensing is an effective method to improve the detection rate in cognitive radio. However, it is vulnerable to spectrum sensing data falsification attacks. In order to improve the robustness, numerous attack prevention schemes have been proposed to identify malicious secondary users (SUs). Nevertheless, most of them neglect to incentivize SUs to send truthful reports. Therefore, an incentive method based on Private-Prior Peer-Prediction with approximate subjective priors is proposed to identify malicious suspects and punish attackers when falsifying the sensing data simultaneously. The theoretical analysis and simulation results demonstrate that honest SUs are rewarded by accurate and truthful sensing results while malicious SUs receive heavy loss for making falsified sensing results. Moreover, a significant improvement of detection rates is demonstrated when there are a large number of malicious SUs conducting cooperative attacks compared to the pure majority rule scheme.","tags":[],"title":"Incentive Attack Prevention for Collaborative Spectrum Sensing: A Peer-Prediction Method","type":"publication"}]