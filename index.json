[{"authors":null,"categories":null,"content":"I am a 5th year Ph.D. candidate in Electrical and Computer Engineering at Cornell University, advised by Professor Christina Delimitrou. I am interested in cloud computing, microservices, ML for systems and computer architecture. My research focuses on building and managing large-scale microservices in datacenters, improving their performance and resource efficiency. Before studying at Cornell, I obtained my B.Eng. degree in Electronic Engineering from Tsinghua University in 2016.\nI was a Ph.D. software engineering intern and student researcher at Google in 2018, 2019, and 2020, hosted by David Lo, Sundar Dev and Qian Xi. During my internship, I did research on using machine learning to improve resource efficiency and detect performance issues of large scale distributed services in Google Cloud.\nðŸŒŸ I am actively looking for full-time job opportunities in industry in both China and North America.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1631478316,"objectID":"41008dc2c308e444b16d91e5e5635685","permalink":"https://gy1005.github.io/author/yu-gan/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yu-gan/","section":"authors","summary":"I am a 5th year Ph.D. candidate in Electrical and Computer Engineering at Cornell University, advised by Professor Christina Delimitrou. I am interested in cloud computing, microservices, ML for systems and computer architecture.","tags":null,"title":"Yu Gan","type":"authors"},{"authors":["Yu Gan","Mingyu Liang","Sundar Dev","David Lo","Christina Delimitrou"],"categories":null,"content":"","date":1618286400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619124762,"objectID":"b5692a7e07b733a8c6c8515e35972a1a","permalink":"https://gy1005.github.io/publication/2021.asplos.sage/","publishdate":"2020-11-20T00:00:00-05:00","relpermalink":"/publication/2021.asplos.sage/","section":"publication","summary":"Cloud applications are increasingly shifting from large monolithic services to complex graphs of loosely-coupled microservices. Despite the advantages of modularity and elasticity microservices offer, they also complicate cluster management and performance debugging, as dependencies between tiers introduce backpressure and cascading QoS violations. Prior work on performance debugging for cloud services either relies on empirical techniques, or uses supervised learning to diagnose the root causes of performance issues, which requires significant application instrumentation, and is difficult to deploy in practice. \nWe present Sage, a machine learning-driven root cause analysis system for interactive cloud microservices that focuses on practicality and scalability. Sage leverages unsupervised ML models to circumvent the overhead of trace labeling, captures the impact of dependencies between microservices to determine the root cause of unpredictable performance online, and applies corrective actions to recover a cloud serviceâ€™s QoS. In experiments on both dedicated local clusters and large clusters on Google Compute Engine we show that Sage consistently achieves over 93% accuracy in correctly identifying the root cause of QoS violations, and improves performance predictability.","tags":[],"title":"Sage: Practical \u0026 Scalable ML-Driven Performance Debugging in Microservices","type":"publication"},{"authors":["Yu Gan","Sundar Dev","David Lo","Christina Delimitrou"],"categories":null,"content":"","date":1589947200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607643896,"objectID":"e65df0b70746e5477ea64fabcbabf1c7","permalink":"https://gy1005.github.io/publication/2020.mlsys.sage/","publishdate":"2020-05-20T00:00:00-04:00","relpermalink":"/publication/2020.mlsys.sage/","section":"publication","summary":"Cloud applications are increasingly shifting from large monolithic services, to complex graphs of loosely-coupled microservices. Despite their advantages, microservices also introduce cascading QoS violations in cloud applications, which are difficult to diagnose and correct. We present Sage, a ML-driven root cause analysis system for interactive cloud microservices. Sage leverages unsupervised learning models to circumvent the overhead of trace labeling, determines the root cause of unpredictable performance online, and applies corrective actions to restore performance. On experiments on both dedicated local clusters and large GCE clusters we show that Sage achieves high root cause detection accuracy and predictable performance.","tags":[],"title":"Sage: Leveraging ML To Diagnose Unpredictable Performance in Cloud Microservices","type":"publication"},{"authors":["Yu Gan","Yanqi Zhang","Dailun Cheng","Ankitha Shetty","Priyal Rathi","Nayantara Katarki","Ariana Bruno","Justin Hu","Brian Ritchken","Brendon Jackson","Kelvin Hu","Meghna Pancholi","Brett Clancy","Chris Colen","Fukang Wen","Catherine Leung","Siyuan Wang","Leon Zaruvinsky","Mateo Espinosa","Yuan He","Christina Delimitrou"],"categories":null,"content":"","date":1587528000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607643896,"objectID":"b2d49b03fd78e25ddb1e8063d212af22","permalink":"https://gy1005.github.io/publication/2020.micro.deathstarbench/","publishdate":"2020-04-22T00:00:00-04:00","relpermalink":"/publication/2020.micro.deathstarbench/","section":"publication","summary":"Cloud services progressively shift from monolithic applications to complex graphs of loosely-coupled microservices. This article aims at understanding the implications microservices have across the system stack, from hardware acceleration and server design, to operating systems and networking, cluster management, and programming frameworks. Toward this effort, we have designed an open-sourced DeathstarBench, a benchmark suite for interactive microservices that is both representative and extensible.","tags":[],"title":"Unveiling the Hardware and Software Implications of Microservices in Cloud and Edge Systems","type":"publication"},{"authors":["Yu Gan","Yanqi Zhang","Kelvin Hu","Dailun Cheng","Yuan He","Meghna Pancholi","Christina Delimitrou"],"categories":null,"content":"","date":1564459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607643896,"objectID":"5607062ccec1ecb67b2e4ba2ff67867c","permalink":"https://gy1005.github.io/publication/2019.sigops.seer/","publishdate":"2019-07-30T00:00:00-04:00","relpermalink":"/publication/2019.sigops.seer/","section":"publication","summary":"Performance unpredictability is a major roadblock towards cloud adoption, and has performance, cost, and revenue ramifications. Predictable performance is even more critical as cloud services transition from monolithic designs to microservices. Detecting QoS violations after they occur in systems with microservices results in long recovery times, as hotspots propagate and amplify across dependent services. We present Seer, an online cloud performance debugging system that leverages deep learning and the massive amount of tracing data cloud systems collect to learn spatial and temporal patterns that translate to QoS violations. Seer combines lightweight distributed RPC-level tracing, with detailed low-level hardware monitoring to signal an upcoming QoS violation, and diagnose the source of unpredictable performance. Once an imminent QoS violation is detected, Seer notifies the cluster manager to take action to avoid performance degradation altogether. We evaluate Seer both in local clusters, and in large-scale deployments of end-to-end applications built with microservices with hundreds of users. We show that Seer correctly anticipates QoS violations 91% of the time, and avoids the QoS violation to begin with in 84% of cases. Finally, we show that Seer can identify application-level design bugs, and provide insights on how to better architect microservices to achieve predictable performance.","tags":[],"title":"Leveraging Deep Learning to Improve Performance Predictability in Cloud Microservices with Seer","type":"publication"},{"authors":["Yu Gan","Yanqi Zhang","Dailun Cheng","Ankitha Shetty","Priyal Rathi","Nayantara Katarki","Ariana Bruno","Justin Hu","Brian Ritchken","Brendon Jackson","Kelvin Hu","Meghna Pancholi","Yuan He","Brett Clancy","Chris Colen","Fukang Wen","Catherine Leung","Siyuan Wang","Leon Zaruvinsky","Mateo Espinosa","Rick Lin","Zhongling Liu","Jake Padilla","Christina Delimitrou"],"categories":null,"content":"","date":1555300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607643896,"objectID":"20e64054b4f06654ee944848c9c61146","permalink":"https://gy1005.github.io/publication/2019.asplos.deathstarbench/","publishdate":"2019-04-15T00:00:00-04:00","relpermalink":"/publication/2019.asplos.deathstarbench/","section":"publication","summary":"Cloud services have recently started undergoing a major shift from monolithic applications, to graphs of hundreds of loosely-coupled microservices. Microservices fundamentally change a lot of assumptions current cloud systems are designed with, and present both opportunities and challenges when optimizing for quality of service (QoS) and utilization. In this paper we explore the implications microservices have across the cloud system stack. We first present DeathStarBench, a novel, open-source benchmark suite built with microservices that is representative of large end-to-end services, modular and extensible. DeathStarBench includes a social network, a media service, an e-commerce site, a banking system, and IoT applications for coordination control of UAV swarms. We then use DeathStarBench to study the architectural characteristics of microservices, their implications in networking and operating systems, their challenges with respect to cluster management, and their trade-offs in terms of application design and programming frameworks. Finally, we explore the tail at scale effects of microservices in real deployments with hundreds of users, and highlight the increased pressure they put on performance predictability.","tags":[],"title":"An Open-Source Benchmark Suite for Microservices and Their Hardware-Software Implications for Cloud and Edge Systems","type":"publication"},{"authors":["Yu Gan","Yanqi Zhang","Kelvin Hu","Yuan He","Meghna Pancholi","Dailun Cheng","Christina Delimitrou"],"categories":null,"content":"","date":1555300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607643896,"objectID":"6262b94a41de3a7061c78e3ea67e0cf9","permalink":"https://gy1005.github.io/publication/2019.asplos.seer/","publishdate":"2019-04-15T00:00:00-04:00","relpermalink":"/publication/2019.asplos.seer/","section":"publication","summary":"Performance unpredictability is a major roadblock towards cloud adoption, and has performance, cost, and revenue ramifications. Predictable performance is even more critical as cloud services transition from monolithic designs to microservices. Detecting QoS violations after they occur in systems with microservices results in long recovery times, as hotspots propagate and amplify across dependent services. We present Seer, an online cloud performance debugging system that leverages deep learning and the massive amount of tracing data cloud systems collect to learn spatial and temporal patterns that translate to QoS violations. Seer combines lightweight distributed RPC-level tracing, with detailed low-level hardware monitoring to signal an upcoming QoS violation, and diagnose the source of unpredictable performance. Once an imminent QoS violation is detected, Seer notifies the cluster manager to take action to avoid performance degradation altogether. We evaluate Seer both in local clusters, and in large-scale deployments of end-to-end applications built with microservices with hundreds of users. We show that Seer correctly anticipates QoS violations 91% of the time, and avoids the QoS violation to begin with in 84% of cases. Finally, we show that Seer can identify applicationlevel design bugs, and provide insights on how to better architect microservices to achieve predictable performance.","tags":[],"title":"Seer: Leveraging Big Data to Navigate the Complexity of Performance Debugging in Cloud Microservices","type":"publication"},{"authors":["Yanqi Zhang","Yu Gan","Christina Delimitrou"],"categories":null,"content":"","date":1553486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607643896,"objectID":"58004ce8776de17340c15e582107ea9c","permalink":"https://gy1005.github.io/publication/2019.ispass.uqsim/","publishdate":"2019-03-25T00:00:00-04:00","relpermalink":"/publication/2019.ispass.uqsim/","section":"publication","summary":"Current cloud services are moving away from monolithic designs and towards graphs of many looselycoupled, single-concerned microservices. Microservices have several advantages, including speeding up development and deployment, allowing specialization of the software infrastructure, and helping with debugging and error isolation. At the same time they introduce several hardware and software challenges. Given that most of the performance and efficiency implications of microservices happen at scales larger than what is available outside production deployments, studying such effects requires designing the right simulation infrastructures. We present ÂµqSim, a scalable and validated queueing network simulator designed specifically for interactive microservices. ÂµqSim provides detailed intra- and inter-microservice models that allow it to faithfully reproduce the behavior of complex, many-tier applications. ÂµqSim is also modular, allowing reuse of individual models across microservices and end-toend applications. We have validated ÂµqSim both against simple and more complex microservices graphs, and have shown that it accurately captures performance in terms of throughput and tail latency. Finally, we use ÂµqSim to model the tail at scale effects of request fanout, and the performance impact of power management in latency-sensitive microservices.","tags":[],"title":"Î¼qSim: Enabling Accurate and Scalable Simulation for Interactive Microservices","type":"publication"},{"authors":["Yu Gan","Meghna Pancholi","Dailun Cheng","Siyuan Hu","Yuan He","Christina Delimitrou"],"categories":null,"content":"","date":1530417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607643896,"objectID":"bff9a51877718e8b8d439bdf85a9e2c6","permalink":"https://gy1005.github.io/publication/2018.hotcloud.seer/","publishdate":"2018-07-01T00:00:00-04:00","relpermalink":"/publication/2018.hotcloud.seer/","section":"publication","summary":"Performance unpredictability in cloud services leads to poor user experience, degraded availability, and has revenue ramifications. Detecting performance degradation a posteriori helps the system take corrective action, but does not avoid the QoS violations. Detecting QoS violations after the fact is even more detrimental when a service consists of hundreds of thousands of loosely-coupled microservices, since performance hiccups can quickly propagate across the dependency graph of microservices. In this work we focus on anticipating QoS violations in cloud settings to mitigate performance unpredictability to begin with. We propose Seer, a cloud runtime that leverages the massive amount of tracing data cloud systems collect over time and a set of practical learning techniques to signal upcoming QoS violations, as well as identify the microservice(s) causing them. Once an imminent QoS violation is detected Seer uses machine-level hardware events to determine the cause of the QoS violation, and adjusts the resource allocations to prevent it. In local clusters with 10 40-core servers and 200-instance clusters on GCE running diverse cloud microservices, we show that Seer correctly anticipates QoS violations 91% of the time, and attributes the violation to the correct microservice in 89% of cases. Finally, Seer detects QoS violations early enough for a corrective action to almost always be applied successfully.","tags":[],"title":"Seer: Leveraging Big Data to Navigate the Increasing Complexity of Cloud Debugging","type":"publication"},{"authors":["Yu Gan","Christina Delimitrou"],"categories":null,"content":"","date":1530417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607643896,"objectID":"b385e9d381d6975227c24b6ae1293d25","permalink":"https://gy1005.github.io/publication/2018.cal.deathstarbench/","publishdate":"2018-07-01T00:00:00-04:00","relpermalink":"/publication/2018.cal.deathstarbench/","section":"publication","summary":"Cloud services have recently undergone a shift from monolithic applications to microservices, with hundreds or thousands of loosely-coupled microservices comprising the end-to-end application. Microservices present both opportunities and challenges when optimizing for quality of service (QoS) and cloud utilization. In this paper we explore the implications cloud microservices have on system bottlenecks, and datacenter server design. We first present and characterize an end-to-end application built using tens of popular open-source microservices that implements a movie renting and streaming service, and is modular and extensible. We then use the end-to-end service to study the scalability and performance bottlenecks of microservices, and highlight implications they have on the design of datacenter hardware. Specifically, we revisit the long-standing debate of brawny versus wimpy cores in the context of microservices, we quantify the I-cache pressure they introduce, and measure the time spent in computation versus communication between microservices over RPCs. As more cloud applications switch to this new programming model, it is increasingly important to revisit the assumptions we have previously used to build and manage cloud systems.","tags":[],"title":"The Architectural Implications of Cloud Microservices","type":"publication"},{"authors":["Yu Gan","Chunxiao Jiang ","Norman C. Beaulieu","Jian Wang","Yong Ren"],"categories":null,"content":"","date":1471320000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607643896,"objectID":"ccb5dbbf2e72302e486ad5aae5a2c4d8","permalink":"https://gy1005.github.io/publication/2016.tcomm.peer-predition/","publishdate":"2016-08-16T00:00:00-04:00","relpermalink":"/publication/2016.tcomm.peer-predition/","section":"publication","summary":"Collaborative spectrum sensing is an effective method to improve detection rates in cognitive radio networks. However, it is vulnerable to spectrum sensing data falsification (SSDF) attacks when malicious secondary users (SUs) report fraudulent sensing data. In order to improve the robustness, numerous attack prevention schemes have been proposed to identify malicious SUs. Nevertheless, most of them neglect to incentivize SUs to send truthful reports. An incentive method based on peer-prediction is proposed to identify malicious suspects, punish attackers, and incentivize SUs to send truthful reports simultaneously for decision fusion. Moreover, continuous peer-prediction derived from the binary case is introduced, which is capable of preventing attacks in the continuous domain. Theoretical analysis and simulation results demonstrate that honest SUs are rewarded for accurate and truthful sensing results, while malicious SUs incur penalty for making falsified sensing reports. A significant improvement of detection rates is obtained by the proposed scheme when there are no more than half of malicious SUs conducting SSDF attacks.","tags":[],"title":"Secure Collaborative Spectrum Sensing: A Peer-Prediction Method","type":"publication"},{"authors":["Yu Gan","Chunxiao Jiang","Wei Zhang","Norman C. Beaulieu","Yong Ren"],"categories":null,"content":"","date":1450155600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607643896,"objectID":"df40f2df8b4535616e5480bcd9187566","permalink":"https://gy1005.github.io/publication/2015.globecom.peer-predition/","publishdate":"2015-12-15T00:00:00-05:00","relpermalink":"/publication/2015.globecom.peer-predition/","section":"publication","summary":"Collaborative spectrum sensing is an effective method to improve the detection rate in cognitive radio. However, it is vulnerable to spectrum sensing data falsification attacks. In order to improve the robustness, numerous attack prevention schemes have been proposed to identify malicious secondary users (SUs). Nevertheless, most of them neglect to incentivize SUs to send truthful reports. Therefore, an incentive method based on Private-Prior Peer-Prediction with approximate subjective priors is proposed to identify malicious suspects and punish attackers when falsifying the sensing data simultaneously. The theoretical analysis and simulation results demonstrate that honest SUs are rewarded by accurate and truthful sensing results while malicious SUs receive heavy loss for making falsified sensing results. Moreover, a significant improvement of detection rates is demonstrated when there are a large number of malicious SUs conducting cooperative attacks compared to the pure majority rule scheme.","tags":[],"title":"Incentive Attack Prevention for Collaborative Spectrum Sensing: A Peer-Prediction Method","type":"publication"}]